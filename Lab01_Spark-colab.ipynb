{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba587a03",
      "metadata": {
        "id": "ba587a03"
      },
      "source": [
        "# COMP7095 - Big Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c252c15",
      "metadata": {
        "id": "7c252c15"
      },
      "source": [
        "## Spark Lab 1: Introduction to Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293d3158",
      "metadata": {
        "id": "293d3158"
      },
      "source": [
        "### Introduction\n",
        "Spark is a general framework for distributed computing that offers high performance for both batch and interactive processing. It supports higher-level tools for SQL and structured data processing, machine learning, graph processing, and stream processing. It exposes APIs for Java, Python, and Scala. In our labs, we mainly use it with Python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80810f68",
      "metadata": {
        "id": "80810f68"
      },
      "source": [
        "## Hand on\n",
        "We are going to use PySpark to load the data from a data file in TSV format and adopt PySpark to do some simply analysis. \n",
        "\n",
        "The file named as \"moview_reviews.tsv\" can be downloaded from the course moodle, too. \n",
        "\n",
        "Using the following code segments to understand how PySpark works.\n",
        "\n",
        "The size of the data file is around 65MB. and the following is the partial layout of the data file:\n",
        "```\n",
        "review\\tsentiment\n",
        "One of the other reviewer...\\tpositive\n",
        "A wonderful little produc...\\tpositive\n",
        "I thought this was a wond...\\tpositive\n",
        "Basically there's a famil...\\tnegative\n",
        "...\n",
        "```\n",
        "\n",
        "Note that values are seperated by a tab ('\\t')."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0742d42",
      "metadata": {
        "id": "c0742d42"
      },
      "source": [
        "Import the required packages and get the instance of the Spark context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1892896",
      "metadata": {
        "id": "c1892896"
      },
      "outputs": [],
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark\n",
        "\n",
        "from pyspark import *\n",
        "from operator import add\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa545c49",
      "metadata": {
        "id": "aa545c49"
      },
      "source": [
        "Define a function to split the values (review and sentiment) of each line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d1d9b7",
      "metadata": {
        "id": "d5d1d9b7"
      },
      "outputs": [],
      "source": [
        "def preprocess(line):\n",
        "    review, sentiment = line.split('\\t')\n",
        "    return sentiment, review"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your local file to Colab.\n",
        "\n",
        "This step requires you to first import the files module from the google.colab library:"
      ],
      "metadata": {
        "id": "Y8UpUGVMcyiv"
      },
      "id": "Y8UpUGVMcyiv"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "NIQwLjcNdBCX"
      },
      "id": "NIQwLjcNdBCX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading files from local file system using Python code.\n",
        "\n",
        "You use the upload method of the files object:"
      ],
      "metadata": {
        "id": "nUM6IfztdNce"
      },
      "id": "nUM6IfztdNce"
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "tDyPVKsddSzq"
      },
      "id": "tDyPVKsddSzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the upload is complete, you can either read it as a file in Colab."
      ],
      "metadata": {
        "id": "vKfmLE2cdYfm"
      },
      "id": "vKfmLE2cdYfm"
    },
    {
      "cell_type": "markdown",
      "id": "11c95c14",
      "metadata": {
        "id": "11c95c14"
      },
      "source": [
        "#### Task 1: Load the data file and create a resilient distributed data (RDD) object. Please complete your code as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542dfc53",
      "metadata": {
        "id": "542dfc53"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "884368c2",
      "metadata": {
        "id": "884368c2"
      },
      "source": [
        "Use the `filter` function to ignore the header row and flip the data to the `preprocess` function. Then, a new RDD object will be created.\n",
        "The `count` function returns the number of rows stored in the RDD object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b646dda1",
      "metadata": {
        "id": "b646dda1"
      },
      "outputs": [],
      "source": [
        "reviews = rdd.filter(lambda x: x != 'review\\tsentiment').map(preprocess)\n",
        "reviews.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c398230",
      "metadata": {
        "id": "7c398230"
      },
      "source": [
        "We can also check what are stored in the RDD object by using the take function. Here we use the `take` function with 1 to get the first item. The parameter represents how many items you want to get from the RDD object."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc59c8d",
      "metadata": {
        "id": "4fc59c8d"
      },
      "source": [
        "Next, we use `filter` function to retrieve all rows with the positive sentiment and create a new RDD object. And, it stores the reviews without the sentiments.\n",
        "Let's also check how many positive reviews!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9dfc4db",
      "metadata": {
        "id": "a9dfc4db"
      },
      "outputs": [],
      "source": [
        "posReviews = reviews.filter(lambda x: x[0] == 'positive').map(lambda x: x[1])\n",
        "posReviews.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "798b7ae0",
      "metadata": {
        "id": "798b7ae0"
      },
      "source": [
        "#### Task 2: Please take the first row of positive reviews. Please complete your code as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac339a60",
      "metadata": {
        "id": "ac339a60"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "012a7782",
      "metadata": {
        "id": "012a7782"
      },
      "source": [
        "#### Task 3: Please a new RDD object for negative reviews. Please complete your code as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7cf131",
      "metadata": {
        "id": "fc7cf131"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6df98249",
      "metadata": {
        "id": "6df98249"
      },
      "source": [
        "Besides, we can find the word frequency using the following simple steps:\n",
        "1. Define a function for splitting each line. It returns a list of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8284226",
      "metadata": {
        "id": "b8284226"
      },
      "outputs": [],
      "source": [
        "def splitWords(line):\n",
        "    values = line.replace(',', ' ').replace('.', ' ').replace('\"', '').split(' ')\n",
        "    data = []\n",
        "    for v in values:\n",
        "        if len(v) > 0:\n",
        "            data.append(v)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e085d8",
      "metadata": {
        "id": "c7e085d8"
      },
      "source": [
        "2. Create a new RDD object from the original RDD object by using the `filter` function and the `splitWords` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7e2d7f",
      "metadata": {
        "id": "ce7e2d7f"
      },
      "outputs": [],
      "source": [
        "wordcounts = rdd.filter(lambda x: x != 'review\\tsentiment').flatMap(splitWords).map(lambda w: (w, 1)).reduceByKey(add)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2323a883",
      "metadata": {
        "id": "2323a883"
      },
      "source": [
        "3. We sort data by the frequency (x[1], the column with index 1) in descending order and retrieve 10 items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d09751",
      "metadata": {
        "id": "28d09751"
      },
      "outputs": [],
      "source": [
        "wordcounts.takeOrdered(10, key=lambda x: -x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86ec67a9",
      "metadata": {
        "id": "86ec67a9"
      },
      "source": [
        "## After using Spark\n",
        "In the end, we should stop the Spark by using the `stop` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b7fa1e",
      "metadata": {
        "id": "c9b7fa1e"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}